{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finding Local Maxima\n",
    "This script demonstrates how we segment our images and find the centroids of our objects.\n",
    "TODO: describe the goal of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the analysis\n",
    "First of all, we need to import the libraries that we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Python import toolbox\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define a number of variables that we are going to use in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RAW_DATASET_ID = 151\n",
    "PROBABILITIES_DATASET_ID = 301\n",
    "OMERO_SERVER = 'localhost'\n",
    "PORT = 4064\n",
    "USER = 'facility_staff_1'\n",
    "PASSWORD = 'facility_staff_1_pw'\n",
    "GROUP = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore your data\n",
    "Now we can connect to OMERO, get some information on the dataset that we want to analyze and explore the data.\n",
    "\n",
    "All the data is arranged in two datasets in the same project. One dataset contains the raw images and the other one \n",
    "contains the probability images extracted using Ilastik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful: True\n",
      "RAW IMAGES\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647.lif [Mark_and_Find_001/Position001] Dimensions(z, c, t, x, y): 30, 4, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647.lif [Mark_and_Find_001/Position002] Dimensions(z, c, t, x, y): 30, 4, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647.lif [Mark_and_Find_001/Position003] Dimensions(z, c, t, x, y): 30, 4, 1, 1576, 1576\n",
      "PROBABILITY IMAGES\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position001_DAPI_Ch1_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position001_DAPI_Ch2_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position001_DAPI_Ch3_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position001_DAPI_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position002_DAPI_Ch1_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position002_DAPI_Ch2_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position002_DAPI_Ch3_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position002_DAPI_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position003_DAPI_Ch1_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position003_DAPI_Ch2_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position003_DAPI_Ch3_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position003_DAPI_Probabilities.npy Dimensions(z, c, t, x, y): 30, 2, 1, 1576, 1576\n"
     ]
    }
   ],
   "source": [
    "# Create a connection\n",
    "conn = toolbox.open_connection(username=USER, password=PASSWORD, group=GROUP,\n",
    "                               host=OMERO_SERVER, port=PORT)\n",
    "print(f'Connection successful: {conn.isConnected()}')\n",
    "\n",
    "# Get all the images contained in the raw dataset\n",
    "raw_dataset = toolbox.get_dataset(connection=conn, dataset_id=RAW_DATASET_ID)\n",
    "raw_images = toolbox.get_dataset_images(dataset=raw_dataset)\n",
    "raw_images = list(raw_images)\n",
    "\n",
    "prob_dataset = toolbox.get_dataset(connection=conn, dataset_id=PROBABILITIES_DATASET_ID)\n",
    "prob_images = toolbox.get_dataset_images(dataset=prob_dataset)\n",
    "prob_images = list(prob_images)\n",
    "\n",
    "print('RAW IMAGES')\n",
    "for image in raw_images[:3]:\n",
    "    print(f'{image.getName()} Dimensions(z, c, t, x, y): {image.getSizeZ()}, {image.getSizeC()}, {image.getSizeT()}, {image.getSizeX()}, {image.getSizeY()}')\n",
    "\n",
    "print('PROBABILITY IMAGES')\n",
    "for image in prob_images[:12]:\n",
    "    print(f'{image.getName()} Dimensions(z, c, t, x, y): {image.getSizeZ()}, {image.getSizeC()}, {image.getSizeT()}, {image.getSizeX()}, {image.getSizeY()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see \n",
    "- a few of the raw images: 3-D stacks of 4 channels (DAPI, X1, X2 and X3) and\n",
    "- one probability image per each channel in the raw images : 3-D stacks of 2 channels representing the probability of being Foreground (channel 0) and the probability of being Background (channel 1)\n",
    "\n",
    "You may generate here a URL to access any of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the raw images go to:\n",
      "http://localhost:8080/webclient/img_detail/101/\n",
      "For the probability images go to:\n",
      "http://localhost:8080/webclient/img_detail/254/\n"
     ]
    }
   ],
   "source": [
    "print('For the raw images go to:')\n",
    "print(f'http://{OMERO_SERVER}:8080/webclient/img_detail/{raw_images[0].getId()}/')\n",
    "print('For the probability images go to:')\n",
    "print(f'http://{OMERO_SERVER}:8080/webclient/img_detail/{prob_images[0].getId()}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the raw values\n",
    "You may load an image as a numpy array ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = toolbox.get_5d_stack(raw_images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "... and see the raw values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1493, 1402],\n",
       "       [ 944,  915]], dtype=uint16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel = 0\n",
    "z_plane = 15\n",
    "x_range = (1100, 1120)\n",
    "y_range = (90, 100)\n",
    "\n",
    "raw_data[0, z_plane, channel, x_range[0]:x_range[1], y_range[0]:y_range[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This raw_data object is a Numpy ndarray (n-dimensional array). \n",
    "This is Python's way to work very efficient with image data.\n",
    "\n",
    "Before moving further we have to arrange the images in the two lists so that every raw image has 4 probability images, one per channel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We are going to create a list of secondary lists where every secondary list \n",
    "# contains the probability images for one single raw image\n",
    "rearranged_prob_images = list()\n",
    "for raw_image in raw_images:  # We are looping through every raw image\n",
    "    name = raw_image.getName()\n",
    "    # We have to remove all the extra characters introduced by Leica. \n",
    "    # Not necessary in principle but as we did it for the probabilities we have to do it again\n",
    "    name = name.replace('/', '_')\n",
    "    name = name.replace('.lif [', '_')\n",
    "    name = name.replace(']', '_')\n",
    "    \n",
    "    rearranged_prob_images.append(list())  # We append an empty secondary list\n",
    "    for subfix in ['DAPI_Probabilities',\n",
    "                   'DAPI_Ch1_Probabilities',\n",
    "                   'DAPI_Ch2_Probabilities',\n",
    "                   'DAPI_Ch3_Probabilities']:\n",
    "        for prob_image in prob_images:\n",
    "            if name in prob_image.getname() and subfix in prob_image.getname():\n",
    "                rearranged_prob_images[-1].append(prob_image)\n",
    "                \n",
    "# We don't need to keep two lists of probability images\n",
    "# so we just replace the old list with the new one\n",
    "prob_images = rearranged_prob_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always good to check visually...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647.lif [Mark_and_Find_001/Position001]\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position001_DAPI_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position001_DAPI_Ch1_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position001_DAPI_Ch2_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position001_DAPI_Ch3_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647.lif [Mark_and_Find_001/Position002]\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position002_DAPI_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position002_DAPI_Ch1_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position002_DAPI_Ch2_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position002_DAPI_Ch3_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647.lif [Mark_and_Find_001/Position003]\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position003_DAPI_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position003_DAPI_Ch1_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position003_DAPI_Ch2_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position003_DAPI_Ch3_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647.lif [Mark_and_Find_001/Position004]\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position004_DAPI_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position004_DAPI_Ch1_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position004_DAPI_Ch2_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position004_DAPI_Ch3_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647.lif [Mark_and_Find_001/Position005]\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position005_DAPI_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position005_DAPI_Ch1_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position005_DAPI_Ch2_Probabilities.npy\n",
      "20181012_S2Rplus_FISH_DAPI_X1-A488_X2-A555_X3-A647_Mark_and_Find_001_Position005_DAPI_Ch3_Probabilities.npy\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(raw_images[i].getName())\n",
    "    for p in prob_images[i]: print(p.getName())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the images\n",
    "Now we have everything ready to start our image analysis. We want to:\n",
    "- Segment each channel using the probability values extracted by Ilastik in stead of the raw values.\n",
    "- Save that segmentation into OMERO.\n",
    "- While we still have the images in memory, we would like to calculate the centroids of the spots this time \n",
    "using the raw pixel values.\n",
    "- We will save the centroid coordinates as a table associated to every image.\n",
    "\n",
    "For most of the image analysis we are going to use scikit-image, a python iamge analysis library built on top of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8c33fe8d4e4d69bc19e7de51f47498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Progress:', max=48)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create here a small widget to follow the progress\n",
    "progress = widgets.IntProgress(value=0, min=0, max=len(raw_images)*4, description='Progress:')\n",
    "display(progress)\n",
    "\n",
    "# We loop through every image in the raw images list\n",
    "for index, raw_image in enumerate(raw_images[:1]):\n",
    "    raw_data = toolbox.get_5d_stack(raw_image)  # We get the raw data. Order is zctxy\n",
    "    \n",
    "    # We now loop through every channel\n",
    "    for ch_nr, ch_prob_image in enumerate(prob_images[index]):\n",
    "        ch_prob_data = toolbox.get_5d_stack(ch_prob_image)\n",
    "        \n",
    "        labels = toolbox.segment_channel(channel=ch_prob_data[:,0,0,:,:].squeeze(),  # We only want to segment on the probability of being foreground\n",
    "                                         min_distance=1,\n",
    "                                         sigma=None,\n",
    "                                         method='hysteresis',\n",
    "                                         hysteresis_levels=(.5, .9))\n",
    "        \n",
    "        # the labels object contains now the segmentation masks for every found object\n",
    "        properties, positions = toolbox.compute_channel_spots_properties(raw_data[:,ch_nr,:,:,:].squeeze(),\n",
    "                                                                         labels)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        progress.value = 1 + (index * ch_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
